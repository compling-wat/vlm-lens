architecture: glamm
model_path: MBZUAI/GLaMM-FullScope
model:
  - image_size: 1024
  - model_max_length: 1536
  - lora_r: 8
  - vision_tower: "openai/clip-vit-large-patch14-336"
  - local_rank: 0
  - use_mm_start_end: true
  - conv_type: "llava_v1"
forward:
  - max_new_tokens: 1
vis_save_path: "./vis_output"
output_db: glamm.db
input_dir: ./data/
prompt: "Describe the color in this image in one word."
modules:
  - model.layers.15.post_attention_layernorm
  - model.layers.31.post_attention_layernorm