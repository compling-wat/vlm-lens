architecture: clip
model_path: openai/clip-vit-base-patch32
model:
  - torch_dtype: auto
dataset:
  - text_dataset_path: wonderwind271/CLEVR_val
  - image_dataset_path: /scratch/ssd004/scratch/hsheta/datasets/CLEVR_v1.0/images
  - text_split: val
  - image_split: val
  - text_column: Q
  - image_column: image_filename
modules:
  - vision_tower.vision_model
